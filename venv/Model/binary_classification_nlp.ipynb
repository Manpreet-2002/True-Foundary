{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84aeacb9",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79adeec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##importing libraries\n",
    "\n",
    "##data manipulation\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "\n",
    "##methods and stopwords text preprocessing\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from emot.emo_unicode import UNICODE_EMOJI # For emojis\n",
    "import pickle\n",
    "\n",
    "##ML Libraries\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eed81107",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\manah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\manah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\manah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\manah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Creating stopwords set\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49b816e",
   "metadata": {},
   "source": [
    "# Loading file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70ae1a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 airline_sentiment  \\\n",
       "0           1          positive   \n",
       "1           3          negative   \n",
       "2           4          negative   \n",
       "3           5          negative   \n",
       "4           6          positive   \n",
       "\n",
       "                                                text  \n",
       "0  @VirginAmerica plus you've added commercials t...  \n",
       "1  @VirginAmerica it's really aggressive to blast...  \n",
       "2  @VirginAmerica and it's a really big bad thing...  \n",
       "3  @VirginAmerica seriously would pay $30 a fligh...  \n",
       "4  @VirginAmerica yes, nearly every time I fly VX...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_dataset(filepath):\n",
    "    \"\"\"\n",
    "    reads the CSV file to return a \n",
    "    dataframe with specified column names\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    return df\n",
    "\n",
    "df = load_dataset(\"airline_sentiment_analysis.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49babc62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text\n",
       "0          positive  @VirginAmerica plus you've added commercials t...\n",
       "1          negative  @VirginAmerica it's really aggressive to blast...\n",
       "2          negative  @VirginAmerica and it's a really big bad thing...\n",
       "3          negative  @VirginAmerica seriously would pay $30 a fligh...\n",
       "4          positive  @VirginAmerica yes, nearly every time I fly VX..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def del_unwanted_cols(df, cols):\n",
    "    \"\"\"\n",
    "    Deletes unwanted columns from dataframe\n",
    "    \"\"\"\n",
    "    for col in cols:\n",
    "        df.drop(col, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "df = del_unwanted_cols(df, ['Unnamed: 0'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06c37f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  @VirginAmerica plus you've added commercials t...          1\n",
       "1  @VirginAmerica it's really aggressive to blast...          0\n",
       "2  @VirginAmerica and it's a really big bad thing...          0\n",
       "3  @VirginAmerica seriously would pay $30 a fligh...          0\n",
       "4  @VirginAmerica yes, nearly every time I fly VX...          1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_categorical(df, col):\n",
    "    \"\"\"\n",
    "    Convert positive to 1 and negative to 0\n",
    "    \"\"\"\n",
    "    dummy = pd.get_dummies(df[col])\n",
    "    df2 = pd.concat((df,dummy), axis=1)\n",
    "    df2.drop(col, axis=1, inplace=True)\n",
    "    df2.drop(\"negative\", axis=1, inplace=True)\n",
    "    df2.rename({'positive':'sentiment'},axis=1, inplace=True)\n",
    "    return df2\n",
    "\n",
    "df = convert_categorical(df, 'airline_sentiment')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4655d2",
   "metadata": {},
   "source": [
    "# Preprocessing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "831674bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hilarious face_with_tears_of_joy. The feeling of making a sale smiling_face_with_sunglasses, The feeling of actually fulfilling orders unamused_face'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UNICODE_EMO = UNICODE_EMOJI\n",
    "# Function for converting emojis into word\n",
    "def convert_emojis(text):\n",
    "    for emot in UNICODE_EMO:\n",
    "        text = text.replace(emot, \"_\".join(UNICODE_EMO[emot].replace(\",\",\"\").replace(\":\",\"\").split()))\n",
    "    return text\n",
    "# Example\n",
    "text1 = \"Hilarious ðŸ˜‚. The feeling of making a sale ðŸ˜Ž, The feeling of actually fulfilling orders ðŸ˜’\"\n",
    "convert_emojis(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f4d88af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_message(message):\n",
    "    \"\"\"\n",
    "    Runs a set of transformational steps to preprocess\n",
    "    the text of the message\n",
    "    \"\"\"\n",
    "    \n",
    "    #Casing -> convert text to lowercase\n",
    "    message = message.lower()\n",
    "    \n",
    "    #Denoising -> remove urls\n",
    "    message = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", message, flags=re.MULTILINE)\n",
    "    \n",
    "    #Denoising -> remove emojis\n",
    "    message = convert_emojis(message)\n",
    "    \n",
    "    #Denoising -> remove punctuations\n",
    "    message = message.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    \n",
    "    #Denoising -> remove @ and # from message\n",
    "    message = re.sub(r\"@[a-z0-9]+\", \"\", message)\n",
    "    message = re.sub(r\"#\", \"\", message)\n",
    "    \n",
    "    #Denoising -> remove RT\n",
    "    message = re.sub(r\"RT[\\s]+\", \"\", message)\n",
    "    \n",
    "    #Tokenization and stop words removal\n",
    "    message_tokens = word_tokenize(message)\n",
    "    filtered_words = [word for word in message_tokens if word not in stop_words]\n",
    "    \n",
    "    #Text normalization -> stemming\n",
    "    ps = PorterStemmer()\n",
    "    stemmed_words = [ps.stem(w) for w in filtered_words]\n",
    "    \n",
    "    #Text normalization -> lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemma_words = [lemmatizer.lemmatize(w, pos='a') for w in stemmed_words]\n",
    "    \n",
    "    return \" \".join(lemma_words)\n",
    "\n",
    "#preprocess_message(\"Hey there, how are you preparing for exams?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd1fdf8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>virginamerica plu youv ad commerci experi tacki</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>virginamerica realli aggress blast obnoxi ente...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>virginamerica realli big bad thing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>virginamerica serious would pay 30 flight seat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>virginamerica ye nearli everi time fli vx â€œ ea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0    virginamerica plu youv ad commerci experi tacki          1\n",
       "1  virginamerica realli aggress blast obnoxi ente...          0\n",
       "2                 virginamerica realli big bad thing          0\n",
       "3  virginamerica serious would pay 30 flight seat...          0\n",
       "4  virginamerica ye nearli everi time fli vx â€œ ea...          1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].apply(preprocess_message)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3a135e",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d41d774",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df['text'].values\n",
    "Y=df['sentiment'].values\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(X,Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867015e2",
   "metadata": {},
   "source": [
    "# TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84bee3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorizer\n",
    "vec = TfidfVectorizer()\n",
    "vec.fit(X_train)\n",
    "pickle.dump(vec, open(\"vectorizer.pickle\", \"wb\"))\n",
    "x_train=vec.transform(X_train)\n",
    "x_test=vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4d5e04",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b4903dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy Score ->  91.0771007796708\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "# fit the training dataset\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, Y_train)\n",
    "\n",
    "# predict the sentiment on validation dataset\n",
    "predictions_LR = lr.predict(x_test)\n",
    "\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"Logistic Regression Accuracy Score -> \",accuracy_score(predictions_LR, Y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65817a60",
   "metadata": {},
   "source": [
    "# Naive Bayes Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2523f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score ->  84.31995379728559\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes Classifier Algorithm\n",
    "\n",
    "# fit the training dataset on the NB classifier\n",
    "Naive = MultinomialNB()\n",
    "Naive.fit(x_train, Y_train)\n",
    "\n",
    "# predict the sentiment on validation dataset\n",
    "predictions_NB = Naive.predict(x_test)\n",
    "\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, Y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826a55a3",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "274dafa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score ->  92.00115506786024\n"
     ]
    }
   ],
   "source": [
    "# Classifier - Algorithm - SVM\n",
    "\n",
    "# fit the training dataset on the classifier\n",
    "SVM = SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(x_train, Y_train)\n",
    "\n",
    "# predict the sentiment on validation dataset\n",
    "predictions_SVM = SVM.predict(x_test)\n",
    "\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Y_test)*100)\n",
    "\n",
    "with open('model_pickle','wb') as f:\n",
    "    pickle.dump(SVM,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8869a492",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_pickle','rb') as f:\n",
    "    mp = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d386cc53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg = \"Hey airline attendant, how are you? Nice to meet you! ðŸ˜ƒ\"\n",
    "msg = preprocess_message(msg)\n",
    "msg = [msg]\n",
    "vectorizer = pickle.load(open(\"vectorizer.pickle\", \"rb\"))\n",
    "msg = vectorizer.transform(msg)\n",
    "#msg = msg[0]\n",
    "mp.predict(msg)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b7eac0",
   "metadata": {},
   "source": [
    "# Training own embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7acc7b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d20728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tokenizer.texts_to_sequences(X_train)\n",
    "x_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c37c4f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = len(tokenizer.word_index) + 1\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "maxlen = 100\n",
    "x_train = pad_sequences(x_train, padding='post', maxlen=maxlen)\n",
    "x_test = pad_sequences(x_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6057570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,Dense, Activation, MaxPool1D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "emb_dim=100\n",
    "model= Sequential()\n",
    "model.add(Embedding(input_dim=vocab, output_dim=emb_dim, input_length=maxlen))\n",
    "model.add(MaxPool1D())\n",
    "model.add(Dense(16,activation=\"relu\"))\n",
    "model.add(Dense(16,activation=\"relu\"))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.add(Flatten())\n",
    "model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9b21704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 100)          885200    \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 50, 100)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense (Dense)               (None, 50, 16)            1616      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50, 16)            272       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 50, 1)             17        \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 50)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 887,105\n",
      "Trainable params: 887,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53b4ed4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "505/505 [==============================] - 4s 6ms/step - loss: 0.5173 - accuracy: 0.1434\n",
      "Epoch 2/35\n",
      "505/505 [==============================] - 3s 6ms/step - loss: 0.4983 - accuracy: 0.1445\n",
      "Epoch 3/35\n",
      "505/505 [==============================] - 3s 6ms/step - loss: 0.4922 - accuracy: 0.1367\n",
      "Epoch 4/35\n",
      "505/505 [==============================] - 3s 6ms/step - loss: 0.4895 - accuracy: 0.1394\n",
      "Epoch 5/35\n",
      "505/505 [==============================] - 3s 6ms/step - loss: 0.4857 - accuracy: 0.1414\n",
      "Epoch 6/35\n",
      "505/505 [==============================] - 3s 6ms/step - loss: 0.4830 - accuracy: 0.1431\n",
      "Epoch 7/35\n",
      "505/505 [==============================] - 3s 6ms/step - loss: 0.4800 - accuracy: 0.1434\n",
      "Epoch 8/35\n",
      "505/505 [==============================] - 3s 6ms/step - loss: 0.4783 - accuracy: 0.1472\n",
      "Epoch 9/35\n",
      "505/505 [==============================] - 3s 6ms/step - loss: 0.4773 - accuracy: 0.1519\n",
      "Epoch 10/35\n",
      "505/505 [==============================] - 3s 6ms/step - loss: 0.4762 - accuracy: 0.1525\n",
      "Epoch 11/35\n",
      "505/505 [==============================] - 3s 6ms/step - loss: 0.4756 - accuracy: 0.1505\n",
      "Epoch 12/35\n",
      "505/505 [==============================] - 3s 7ms/step - loss: 0.4756 - accuracy: 0.1556\n",
      "Epoch 13/35\n",
      "505/505 [==============================] - 4s 7ms/step - loss: 0.4747 - accuracy: 0.1499\n",
      "Epoch 14/35\n",
      "505/505 [==============================] - 3s 6ms/step - loss: 0.4748 - accuracy: 0.1538\n",
      "Epoch 15/35\n",
      "505/505 [==============================] - 4s 7ms/step - loss: 0.4740 - accuracy: 0.1585\n",
      "Epoch 16/35\n",
      "505/505 [==============================] - 3s 6ms/step - loss: 0.4740 - accuracy: 0.1547\n",
      "Epoch 17/35\n",
      "505/505 [==============================] - 3s 6ms/step - loss: 0.4743 - accuracy: 0.1567\n",
      "Epoch 18/35\n",
      "505/505 [==============================] - 3s 7ms/step - loss: 0.4735 - accuracy: 0.1529\n",
      "Epoch 19/35\n",
      "505/505 [==============================] - 4s 7ms/step - loss: 0.4732 - accuracy: 0.1510\n",
      "Epoch 20/35\n",
      "505/505 [==============================] - 4s 7ms/step - loss: 0.4739 - accuracy: 0.1590\n",
      "Epoch 21/35\n",
      "505/505 [==============================] - 4s 8ms/step - loss: 0.4732 - accuracy: 0.1577\n",
      "Epoch 22/35\n",
      "505/505 [==============================] - 4s 7ms/step - loss: 0.4731 - accuracy: 0.1547\n",
      "Epoch 23/35\n",
      "505/505 [==============================] - 4s 7ms/step - loss: 0.4728 - accuracy: 0.1577\n",
      "Epoch 24/35\n",
      "505/505 [==============================] - 3s 7ms/step - loss: 0.4728 - accuracy: 0.1592\n",
      "Epoch 25/35\n",
      "505/505 [==============================] - 3s 7ms/step - loss: 0.4727 - accuracy: 0.1582\n",
      "Epoch 26/35\n",
      "505/505 [==============================] - 3s 7ms/step - loss: 0.4729 - accuracy: 0.1603\n",
      "Epoch 27/35\n",
      "505/505 [==============================] - 3s 7ms/step - loss: 0.4723 - accuracy: 0.1592\n",
      "Epoch 28/35\n",
      "505/505 [==============================] - 3s 7ms/step - loss: 0.4727 - accuracy: 0.1587\n",
      "Epoch 29/35\n",
      "505/505 [==============================] - 3s 7ms/step - loss: 0.4726 - accuracy: 0.1580\n",
      "Epoch 30/35\n",
      "505/505 [==============================] - 3s 7ms/step - loss: 0.4724 - accuracy: 0.1602\n",
      "Epoch 31/35\n",
      "505/505 [==============================] - 3s 7ms/step - loss: 0.4720 - accuracy: 0.1590\n",
      "Epoch 32/35\n",
      "505/505 [==============================] - 3s 7ms/step - loss: 0.4722 - accuracy: 0.1586\n",
      "Epoch 33/35\n",
      "505/505 [==============================] - 3s 7ms/step - loss: 0.4723 - accuracy: 0.1607\n",
      "Epoch 34/35\n",
      "505/505 [==============================] - 3s 7ms/step - loss: 0.4723 - accuracy: 0.1588\n",
      "Epoch 35/35\n",
      "505/505 [==============================] - 3s 7ms/step - loss: 0.4720 - accuracy: 0.1581\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, Y_train,epochs=35,verbose=True,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5dcebbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/109 [==============================] - 0s 1ms/step - loss: 0.5537 - accuracy: 0.1582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5537469387054443, 0.1582442969083786]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score=model.evaluate(x_test,Y_test)\n",
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7f8e635c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It has only 15.82% accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvkernel",
   "language": "python",
   "name": "venvkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f536259478d8bf05f6395aa2f4f86de10d38bbe701ddcdbe13be86ff33256db8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
